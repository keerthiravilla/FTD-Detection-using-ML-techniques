# -*- coding: utf-8 -*-
"""Fsl_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AtNxK1wjzigNp3w6JtF3NJNIbIxK6z2E
"""

# Commented out IPython magic to ensure Python compatibility.
#Multi-class Classification
import zipfile
import nibabel as nib
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.utils import make_grid
import numpy as np
import pandas as pd
import pickle
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import glob
from torch.autograd import Variable
from torchvision import models
from torch.nn import Module,  Linear, ReLU, CrossEntropyLoss, Sequential, Conv3d, MaxPool3d, Softmax, BatchNorm3d
from torch.optim import Adam
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import seaborn as sn
import torch.optim as optim
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import matthews_corrcoef
from torchsummary import summary
from sklearn.linear_model import LogisticRegression
import scipy
from scipy.stats import t
from tqdm import tqdm
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import matthews_corrcoef
from sklearn.manifold import TSNE
from sklearn import metrics
import seaborn as sns
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive/')

import os
#walk through directory and list through files
for dirpath, dirnames, filenames in os.walk("/content/drive/My Drive/ADNI_full"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
len(filenames)

#Get the class names
import numpy as np
import pathlib
data_dir = pathlib.Path('/content/drive/My Drive/ADNI_full')
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)

model = torch.jit.load('/content/drive/MyDrive/feature_extractor.pt')
model.eval()

class ResNet(nn.Module):
    def __init__(self):
        super(ResNet, self).__init__()
        self.avgpool = nn.Sequential(*list(model.fc.children())[:-4]
        )
    def forward(self, x):
        x = self.avgpool(x).flatten(start_dim=1)
        return x


model_new = ResNet()

model_new.eval()

"""#3 Way 5-Short Classification

#Loading CN samples
"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/FSL_5/Support_set/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

"""#Loading BV Samples"""

BV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_5/Support_set/BV/*.nii')
BVftd_files = BV_ftd
BVfiles = len(BVftd_files)
print('The total number of nifti files:', str(BVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

BV_ftd_images = np.zeros((BVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(BV_ftd_images.shape)
#Load nifti files into array

for i in  range(BVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, BVfiles))
    BV_ftd_img = nib.load(BVftd_files[i])
    BV_ftd_img = BV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    BV_ftd_img = np.transpose(BV_ftd_img, (2,0,1))
    BV_ftd_img = np.flip(BV_ftd_img)
    
    BV_ftd_images[i, :,:,:, 0] = np.nan_to_num(BV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', BV_ftd_images.shape)

#Making y-labels
label_BV_ftd = np.full(len(BV_ftd_images),1)
print('label_BV_ftd', label_BV_ftd.shape)
labels_BV_ftd = np.full((len(BV_ftd_images),),1)
print('label_BV_ftd', labels_BV_ftd.shape)

"""#Loading SV Samples"""

SV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_5/Support_set/SV/*.nii')
SVftd_files = SV_ftd
SVfiles = len(SVftd_files)
print('The total number of nifti files:', str(SVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

SV_ftd_images = np.zeros((SVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(SV_ftd_images.shape)
#Load nifti files into array

for i in  range(SVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, SVfiles))
    SV_ftd_img = nib.load(SVftd_files[i])
    SV_ftd_img = SV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    SV_ftd_img = np.transpose(SV_ftd_img, (2,0,1))
    SV_ftd_img = np.flip(SV_ftd_img)
    
    SV_ftd_images[i, :,:,:, 0] = np.nan_to_num(SV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', SV_ftd_images.shape)

#Making y-labels
label_SV_ftd = np.full(len(SV_ftd_images),2)
print('label_SV_ftd', label_SV_ftd.shape)
labels_SV_ftd = np.full((len(SV_ftd_images),),2)
print('label_SV_ftd', labels_SV_ftd.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images,BV_ftd_images, SV_ftd_images), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,label_BV_ftd,label_SV_ftd), axis=0)
print('y data in  of train size: ', y.shape)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(15,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset = TensorDataset(X,y)
test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

from sklearn.model_selection import train_test_split
#batch_size=32
support_xs,query_xs, support_ys,query_ys =train_test_split(X,y, test_size=0.2, random_state=42)


(support_xs.shape, support_ys.shape),(query_xs.shape, query_ys.shape), (support_xs.dtype, support_ys.dtype), (query_xs.dtype, query_ys.dtype)

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset = TensorDataset(support_xs,support_ys)
dataset1 = TensorDataset(query_xs,query_ys)

test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
validataion_loader = DataLoader(dataset1, batch_size=BATCH_SIZE,shuffle=False)

torch.manual_seed(22)
support_list=[]
support_ys_list=[]
model_new.eval()
with torch.no_grad():
  for data in test_loader:
    support_xs,support_ys = data
    batch_size, channel, height, width, depth = support_xs.size()
    support_xs = support_xs.view(-1, channel, height, width, depth)
    support_xs = support_xs.view(-1, channel, height, width,depth)
    feat_support = model_new(support_xs.data).view(support_xs.size(0), -1)
    feat_support = feat_support.detach().cpu().numpy()
    support_list.append(feat_support)
    #print(len(feat_support))
    support_ys = support_ys.view(-1).numpy()
    support_ys_list.append(support_ys)
    #print(len(support_ys))

support_list=np.vstack(support_list)
len(support_list)

support_list

support_ys_list= np.hstack(support_ys_list)
len(support_ys_list)

support_ys_list

support_list.shape

"""#Query Set"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/FSL_5/Query_set/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

BV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_5/Query_set/BV/*.nii')
BVftd_files = BV_ftd
BVfiles = len(BVftd_files)
print('The total number of nifti files:', str(BVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

BV_ftd_images = np.zeros((BVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(BV_ftd_images.shape)
#Load nifti files into array

for i in  range(BVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, BVfiles))
    BV_ftd_img = nib.load(BVftd_files[i])
    BV_ftd_img = BV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    BV_ftd_img = np.transpose(BV_ftd_img, (2,0,1))
    BV_ftd_img = np.flip(BV_ftd_img)
    
    BV_ftd_images[i, :,:,:, 0] = np.nan_to_num(BV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', BV_ftd_images.shape)

#Making y-labels
label_BV_ftd = np.full(len(BV_ftd_images),1)
print('label_BV_ftd', label_BV_ftd.shape)
labels_BV_ftd = np.full((len(BV_ftd_images),),1)
print('label_BV_ftd', labels_BV_ftd.shape)

SV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_5/Query_set/SV/*.nii')
SVftd_files = SV_ftd
SVfiles = len(SVftd_files)
print('The total number of nifti files:', str(SVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

SV_ftd_images = np.zeros((SVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(SV_ftd_images.shape)
#Load nifti files into array

for i in  range(SVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, SVfiles))
    SV_ftd_img = nib.load(SVftd_files[i])
    SV_ftd_img = SV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    SV_ftd_img = np.transpose(SV_ftd_img, (2,0,1))
    SV_ftd_img = np.flip(SV_ftd_img)
    
    SV_ftd_images[i, :,:,:, 0] = np.nan_to_num(SV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', SV_ftd_images.shape)

#Making y-labels
label_SV_ftd = np.full(len(SV_ftd_images),2)
print('label_SV_ftd', label_SV_ftd.shape)
labels_SV_ftd = np.full((len(SV_ftd_images),),2)
print('label_SV_ftd', labels_SV_ftd.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images,BV_ftd_images, SV_ftd_images), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,label_BV_ftd,label_SV_ftd), axis=0)
print('y data in  of train size: ', y.shape)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(9,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset = TensorDataset(X,y)
validation_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)

torch.manual_seed(23)
query_list=[]
query_ys_list=[]
model.eval()
with torch.no_grad():
  for data in validation_loader:
    query_xs,query_ys = data
    batch_size, channel, height, width, depth = query_xs.size()
    query_xs = query_xs.view(-1, channel, height, width, depth)
    query_xs = query_xs.view(-1, channel, height, width,depth)
    feat_query = model_new(query_xs.data).view(query_xs.size(0), -1)
    feat_query = feat_query.detach().cpu().numpy()
    query_list.append(feat_query)
    #print(len(feat_query))
    query_ys = query_ys.view(-1).numpy()
    query_ys_list.append(query_ys)
    #print(len(query_ys))

query_list=np.vstack(query_list)
len(query_list)

query_ys_list= np.hstack(query_ys_list)
len(query_ys_list)

query_ys_list

clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
clf.fit(support_list, support_ys_list)

clf.score(support_list, support_ys_list)

clf.score(query_list, query_ys_list)

query_ys_pred = clf.predict(query_list)

acc_phi=[]
acc_phi.append(metrics.matthews_corrcoef(query_ys_list, query_ys_pred))

acc_phi

acc=[]
acc.append(metrics.accuracy_score(query_ys_list, query_ys_pred))

acc

from sklearn.metrics import classification_report
y_true = query_ys_list
y_pred = query_ys_pred
target_names = ['CN', 'FTD_BV','FTD_SV']
print(classification_report(y_true, y_pred, target_names=target_names))

cnf_matrix=metrics.confusion_matrix(query_ys_list, query_ys_pred)
cnf_matrix

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#fig, ax = plt.subplots(figsize=(10, 5))
np.random.seed(0)

labels = ['CN', 'BV', 'SV']

cm = confusion_matrix(query_ys_list, query_ys_pred)
ConfusionMatrixDisplay(cm, display_labels=labels).plot()

"""#Cross Validation"""

X=np.concatenate((support_list,query_list))
len(X)

y=np.concatenate((support_ys_list,query_ys_list))
len(y)

from sklearn.model_selection import cross_val_score
clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
scores = cross_val_score(clf, X, y, cv=5)
scores

print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))

"""#4 Way 10 Shot Classification

"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Support_set/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

BV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Support_set/BV/*.nii')
BVftd_files = BV_ftd
BVfiles = len(BVftd_files)
print('The total number of nifti files:', str(BVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

BV_ftd_images = np.zeros((BVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(BV_ftd_images.shape)
#Load nifti files into array

for i in  range(BVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, BVfiles))
    BV_ftd_img = nib.load(BVftd_files[i])
    BV_ftd_img = BV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    BV_ftd_img = np.transpose(BV_ftd_img, (2,0,1))
    BV_ftd_img = np.flip(BV_ftd_img)
    
    BV_ftd_images[i, :,:,:, 0] = np.nan_to_num(BV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', BV_ftd_images.shape)

#Making y-labels
label_BV_ftd = np.full(len(BV_ftd_images),1)
print('label_BV_ftd', label_BV_ftd.shape)
labels_BV_ftd = np.full((len(BV_ftd_images),),1)
print('label_BV_ftd', labels_BV_ftd.shape)

SV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Support_set/SV/*.nii')
SVftd_files = SV_ftd
SVfiles = len(SVftd_files)
print('The total number of nifti files:', str(SVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

SV_ftd_images = np.zeros((SVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(SV_ftd_images.shape)
#Load nifti files into array

for i in  range(SVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, SVfiles))
    SV_ftd_img = nib.load(SVftd_files[i])
    SV_ftd_img = SV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    SV_ftd_img = np.transpose(SV_ftd_img, (2,0,1))
    SV_ftd_img = np.flip(SV_ftd_img)
    
    SV_ftd_images[i, :,:,:, 0] = np.nan_to_num(SV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', SV_ftd_images.shape)

#Making y-labels
label_SV_ftd = np.full(len(SV_ftd_images),2)
print('label_SV_ftd', label_SV_ftd.shape)
labels_SV_ftd = np.full((len(SV_ftd_images),),2)
print('label_SV_ftd', labels_SV_ftd.shape)

PNFA_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Support_set/PNFA/*.nii')
PNFAftd_files = PNFA_ftd
PNFAfiles = len(PNFAftd_files)
print('The total number of nifti files:', str(PNFAfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

PNFA_ftd_images = np.zeros((PNFAfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(PNFA_ftd_images.shape)
#Load nifti files into array

for i in  range(PNFAfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, PNFAfiles))
    PNFA_ftd_img = nib.load(PNFAftd_files[i])
    PNFA_ftd_img = PNFA_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    PNFA_ftd_img = np.transpose(PNFA_ftd_img, (2,0,1))
    PNFA_ftd_img = np.flip(PNFA_ftd_img)
    
    PNFA_ftd_images[i, :,:,:, 0] = np.nan_to_num(PNFA_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', PNFA_ftd_images.shape)

#Making y-labels
label_PNFA_ftd = np.full(len(PNFA_ftd_images),3)
print('label_PNFA_ftd', label_PNFA_ftd.shape)
labels_PNFA_ftd = np.full((len(PNFA_ftd_images),),3)
print('label_PNFA_ftd', labels_PNFA_ftd.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images,BV_ftd_images, SV_ftd_images,PNFA_ftd_images), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,label_BV_ftd,label_SV_ftd, label_PNFA_ftd), axis=0)
print('y data in  of train size: ', y.shape)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(40,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from torch.utils.data import DataLoader,TensorDataset,random_split
BATCH_SIZE = 10
dataset = TensorDataset(X,y)
#train, valid = random_split(dataset,[32,8])
test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

torch.manual_seed(12)
support_list=[]
support_ys_list=[]
model_new.eval()
with torch.no_grad():
  for data in test_loader:
    support_xs,support_ys = data
    batch_size, channel, height, width, depth = support_xs.size()
    support_xs = support_xs.view(-1, channel, height, width, depth)
    support_xs = support_xs.view(-1, channel, height, width,depth)
    feat_support = model_new(support_xs.data).view(support_xs.size(0), -1)
    feat_support = feat_support.detach().cpu().numpy()
    support_list.append(feat_support)
    #print(len(feat_support))
    support_ys = support_ys.view(-1).numpy()
    support_ys_list.append(support_ys)
    #print(len(support_ys))

support_list=np.vstack(support_list)
len(support_list)

support_ys_list= np.hstack(support_ys_list)
len(support_ys_list)

support_list.shape

support_ys_list

"""#Query Set"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Query_set/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

BV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Query_set/BV/*.nii')
BVftd_files = BV_ftd
BVfiles = len(BVftd_files)
print('The total number of nifti files:', str(BVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

BV_ftd_images = np.zeros((BVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(BV_ftd_images.shape)
#Load nifti files into array

for i in  range(BVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, BVfiles))
    BV_ftd_img = nib.load(BVftd_files[i])
    BV_ftd_img = BV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    BV_ftd_img = np.transpose(BV_ftd_img, (2,0,1))
    BV_ftd_img = np.flip(BV_ftd_img)
    
    BV_ftd_images[i, :,:,:, 0] = np.nan_to_num(BV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', BV_ftd_images.shape)

#Making y-labels
label_BV_ftd = np.full(len(BV_ftd_images),1)
print('label_BV_ftd', label_BV_ftd.shape)
labels_BV_ftd = np.full((len(BV_ftd_images),),1)
print('label_BV_ftd', labels_BV_ftd.shape)

SV_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Query_set/SV/*.nii')
SVftd_files = SV_ftd
SVfiles = len(SVftd_files)
print('The total number of nifti files:', str(SVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

SV_ftd_images = np.zeros((SVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(SV_ftd_images.shape)
#Load nifti files into array

for i in  range(SVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, SVfiles))
    SV_ftd_img = nib.load(SVftd_files[i])
    SV_ftd_img = SV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    SV_ftd_img = np.transpose(SV_ftd_img, (2,0,1))
    SV_ftd_img = np.flip(SV_ftd_img)
    
    SV_ftd_images[i, :,:,:, 0] = np.nan_to_num(SV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', SV_ftd_images.shape)

#Making y-labels
label_SV_ftd = np.full(len(SV_ftd_images),2)
print('label_SV_ftd', label_SV_ftd.shape)
labels_SV_ftd = np.full((len(SV_ftd_images),),2)
print('label_SV_ftd', labels_SV_ftd.shape)

PNFA_ftd = glob.glob(r'/content/drive/MyDrive/FSL_10/Query_set/PNFA/*.nii')
PNFAftd_files = PNFA_ftd
PNFAfiles = len(PNFAftd_files)
print('The total number of nifti files:', str(PNFAfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

PNFA_ftd_images = np.zeros((PNFAfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(PNFA_ftd_images.shape)
#Load nifti files into array

for i in  range(PNFAfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, PNFAfiles))
    PNFA_ftd_img = nib.load(PNFAftd_files[i])
    PNFA_ftd_img = PNFA_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    PNFA_ftd_img = np.transpose(PNFA_ftd_img, (2,0,1))
    PNFA_ftd_img = np.flip(PNFA_ftd_img)
    
    PNFA_ftd_images[i, :,:,:, 0] = np.nan_to_num(PNFA_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', PNFA_ftd_images.shape)

#Making y-labels
label_PNFA_ftd = np.full(len(PNFA_ftd_images),3)
print('label_PNFA_ftd', label_PNFA_ftd.shape)
labels_PNFA_ftd = np.full((len(PNFA_ftd_images),),3)
print('label_PNFA_ftd', labels_PNFA_ftd.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images,BV_ftd_images, SV_ftd_images,PNFA_ftd_images), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,label_BV_ftd,label_SV_ftd, label_PNFA_ftd), axis=0)
print('y data in  of train size: ', y.shape)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(12,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset1 = TensorDataset(X,y)
validation_loader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=False)

torch.manual_seed(13)
query_list=[]
query_ys_list=[]
model.eval()
with torch.no_grad():
  for data in validation_loader:
    query_xs,query_ys = data
    batch_size, channel, height, width, depth = query_xs.size()
    query_xs = query_xs.view(-1, channel, height, width, depth)
    query_xs = query_xs.view(-1, channel, height, width,depth)
    feat_query = model_new(query_xs.data).view(query_xs.size(0), -1)
    feat_query = feat_query.detach().cpu().numpy()
    query_list.append(feat_query)
    #print(len(feat_query))
    query_ys = query_ys.view(-1).numpy()
    query_ys_list.append(query_ys)
    #print(len(query_ys))

query_list=np.vstack(query_list)
len(query_list)

query_ys_list= np.hstack(query_ys_list)
len(query_ys_list)

query_ys_list

from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score
#Use to estimate the performance of the model based on accuracy, precision, recall, f1 score, AUC ROCCURVE, CM
def evaluation_metrics(Y_test, Y_pre, target_names):
    #scores
    print("Accuracy :",accuracy_score(Y_test,Y_pre))
    print("Precision :",precision_score(Y_test,Y_pre))
    print("Recall :",recall_score(Y_test,Y_pre))
    print("F1 Score :",f1_score(Y_test,Y_pre))

    print(classification_report(Y_test, Y_pre, target_names=target_names))

    #AUC
    fpr, tpr, _ = roc_curve(Y_test,Y_pre)
    auc = roc_auc_score(Y_test,Y_pre)
    print("AUC :", auc)

    #ROC
    plt.plot(fpr,tpr,label="uc={:.3f})".format(auc))
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC curve')
    plt.legend(loc=4)
    plt.show()

    #CM matrix
    matrix = confusion_matrix(Y_test, Y_pre)
    cm = pd.DataFrame(matrix, index=target_names, columns=target_names)

    sns.heatmap(cm, annot=True, cbar=None, cmap="Blues", fmt = 'g')
    plt.title("Confusion Matrix"), plt.tight_layout()
    plt.ylabel("True Class"), plt.xlabel("Predicted Class")
    plt.show()

def logistic(X_train,X_test,Y_train,Y_test):
    model=LogisticRegression()
    model.fit(X_train,Y_train)
    Y_pre=model.predict(X_test)
    target_names = ['CN', 'FTD_BV','FTD_SV','FTD_PNFA']
    evaluation_metrics(Y_test, Y_pre, target_names)

logistic(support_list, query_list,support_ys_list,query_ys_list)

clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
clf.fit(support_list, support_ys_list)

clf.score(support_list, support_ys_list)

query_ys_pred = clf.predict(query_list)

acc_phi=[]
acc_phi.append(metrics.matthews_corrcoef(query_ys_list, query_ys_pred))

acc_phi

acc=[]
acc.append(metrics.accuracy_score(query_ys_list, query_ys_pred))

acc

from sklearn.metrics import classification_report
y_true = query_ys_list
y_pred = query_ys_pred
target_names = ['CN', 'FTD_BV','FTD_SV','FTD_PNFA']
print(classification_report(y_true, y_pred, target_names=target_names))

cnf_matrix=metrics.confusion_matrix(query_ys_list, query_ys_pred)
cnf_matrix

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#fig, ax = plt.subplots(figsize=(10, 5))
np.random.seed(0)

labels = ['CN', 'FTD_BV','FTD_SV','FTD_PNFA']

cm = confusion_matrix(query_ys_list, query_ys_pred)
ConfusionMatrixDisplay(cm, display_labels=labels).plot()

class_names=[0,1,2,3] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print("Accuracy:",metrics.accuracy_score(query_ys_list, query_ys_pred))

"""#Cross Validation"""

X=np.concatenate((support_list,query_list))
len(X)

y=np.concatenate((support_ys_list,query_ys_list))
len(y)

from sklearn.model_selection import cross_val_score
clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
scores = cross_val_score(clf, X, y, cv=5)
scores

print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))

"""#4 Shot 5 Way Classification"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Support set/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

BV_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Support set/BV/*.nii')
BVftd_files = BV_ftd
BVfiles = len(BVftd_files)
print('The total number of nifti files:', str(BVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

BV_ftd_images = np.zeros((BVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(BV_ftd_images.shape)
#Load nifti files into array

for i in  range(BVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, BVfiles))
    BV_ftd_img = nib.load(BVftd_files[i])
    BV_ftd_img = BV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    BV_ftd_img = np.transpose(BV_ftd_img, (2,0,1))
    BV_ftd_img = np.flip(BV_ftd_img)
    
    BV_ftd_images[i, :,:,:, 0] = np.nan_to_num(BV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', BV_ftd_images.shape)

#Making y-labels
label_BV_ftd = np.full(len(BV_ftd_images),1)
print('label_BV_ftd', label_BV_ftd.shape)
labels_BV_ftd = np.full((len(BV_ftd_images),),1)
print('label_BV_ftd', labels_BV_ftd.shape)

SV_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Support set/SV/*.nii')
SVftd_files = SV_ftd
SVfiles = len(SVftd_files)
print('The total number of nifti files:', str(SVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

SV_ftd_images = np.zeros((SVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(SV_ftd_images.shape)
#Load nifti files into array

for i in  range(SVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, SVfiles))
    SV_ftd_img = nib.load(SVftd_files[i])
    SV_ftd_img = SV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    SV_ftd_img = np.transpose(SV_ftd_img, (2,0,1))
    SV_ftd_img = np.flip(SV_ftd_img)
    
    SV_ftd_images[i, :,:,:, 0] = np.nan_to_num(SV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', SV_ftd_images.shape)

#Making y-labels
label_SV_ftd = np.full(len(SV_ftd_images),2)
print('label_SV_ftd', label_SV_ftd.shape)
labels_SV_ftd = np.full((len(SV_ftd_images),),2)
print('label_SV_ftd', labels_SV_ftd.shape)

PNFA_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Support set/PNFA/*.nii')
PNFAftd_files = PNFA_ftd
PNFAfiles = len(PNFAftd_files)
print('The total number of nifti files:', str(PNFAfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

PNFA_ftd_images = np.zeros((PNFAfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(PNFA_ftd_images.shape)
#Load nifti files into array

for i in  range(PNFAfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, PNFAfiles))
    PNFA_ftd_img = nib.load(PNFAftd_files[i])
    PNFA_ftd_img = PNFA_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    PNFA_ftd_img = np.transpose(PNFA_ftd_img, (2,0,1))
    PNFA_ftd_img = np.flip(PNFA_ftd_img)
    
    PNFA_ftd_images[i, :,:,:, 0] = np.nan_to_num(PNFA_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', PNFA_ftd_images.shape)

#Making y-labels
label_PNFA_ftd = np.full(len(PNFA_ftd_images),3)
print('label_PNFA_ftd', label_PNFA_ftd.shape)
labels_PNFA_ftd = np.full((len(PNFA_ftd_images),),3)
print('label_PNFA_ftd', labels_PNFA_ftd.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images,BV_ftd_images, SV_ftd_images,PNFA_ftd_images), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,label_BV_ftd,label_SV_ftd, label_PNFA_ftd), axis=0)
print('y data in  of train size: ', y.shape)

X.shape,y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(20,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from torch.utils.data import DataLoader,TensorDataset,random_split
BATCH_SIZE = 10
dataset = TensorDataset(X,y)
#train, valid = random_split(dataset,[32,8])
test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

torch.manual_seed(42)
support_list=[]
support_ys_list=[]
model_new.eval()
with torch.no_grad():
  for data in test_loader:
    support_xs,support_ys = data
    batch_size, channel, height, width, depth = support_xs.size()
    support_xs = support_xs.view(-1, channel, height, width, depth)
    support_xs = support_xs.view(-1, channel, height, width,depth)
    feat_support = model_new(support_xs.data).view(support_xs.size(0), -1)
    feat_support = feat_support.detach().cpu().numpy()
    support_list.append(feat_support)
    #print(len(feat_support))
    support_ys = support_ys.view(-1).numpy()
    support_ys_list.append(support_ys)
    #print(len(support_ys))

support_list=np.vstack(support_list)
len(support_list)

support_ys_list= np.hstack(support_ys_list)
len(support_ys_list)

support_list.shape

support_ys_list

"""#Query Set"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Query_set/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

BV_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Query_set/BV/*.nii')
BVftd_files = BV_ftd
BVfiles = len(BVftd_files)
print('The total number of nifti files:', str(BVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

BV_ftd_images = np.zeros((BVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(BV_ftd_images.shape)
#Load nifti files into array

for i in  range(BVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, BVfiles))
    BV_ftd_img = nib.load(BVftd_files[i])
    BV_ftd_img = BV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    BV_ftd_img = np.transpose(BV_ftd_img, (2,0,1))
    BV_ftd_img = np.flip(BV_ftd_img)
    
    BV_ftd_images[i, :,:,:, 0] = np.nan_to_num(BV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', BV_ftd_images.shape)

#Making y-labels
label_BV_ftd = np.full(len(BV_ftd_images),1)
print('label_BV_ftd', label_BV_ftd.shape)
labels_BV_ftd = np.full((len(BV_ftd_images),),1)
print('label_BV_ftd', labels_BV_ftd.shape)

SV_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Query_set/SV/*.nii')
SVftd_files = SV_ftd
SVfiles = len(SVftd_files)
print('The total number of nifti files:', str(SVfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

SV_ftd_images = np.zeros((SVfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(SV_ftd_images.shape)
#Load nifti files into array

for i in  range(SVfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, SVfiles))
    SV_ftd_img = nib.load(SVftd_files[i])
    SV_ftd_img = SV_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    SV_ftd_img = np.transpose(SV_ftd_img, (2,0,1))
    SV_ftd_img = np.flip(SV_ftd_img)
    
    SV_ftd_images[i, :,:,:, 0] = np.nan_to_num(SV_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', SV_ftd_images.shape)

#Making y-labels
label_SV_ftd = np.full(len(SV_ftd_images),2)
print('label_SV_ftd', label_SV_ftd.shape)
labels_SV_ftd = np.full((len(SV_ftd_images),),2)
print('label_SV_ftd', labels_SV_ftd.shape)

PNFA_ftd = glob.glob(r'/content/drive/MyDrive/4_FSL_5/Query_set/PNFA/*.nii')
PNFAftd_files = PNFA_ftd
PNFAfiles = len(PNFAftd_files)
print('The total number of nifti files:', str(PNFAfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

PNFA_ftd_images = np.zeros((PNFAfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(PNFA_ftd_images.shape)
#Load nifti files into array

for i in  range(PNFAfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, PNFAfiles))
    PNFA_ftd_img = nib.load(PNFAftd_files[i])
    PNFA_ftd_img = PNFA_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    PNFA_ftd_img = np.transpose(PNFA_ftd_img, (2,0,1))
    PNFA_ftd_img = np.flip(PNFA_ftd_img)
    
    PNFA_ftd_images[i, :,:,:, 0] = np.nan_to_num(PNFA_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', PNFA_ftd_images.shape)

#Making y-labels
label_PNFA_ftd = np.full(len(PNFA_ftd_images),3)
print('label_PNFA_ftd', label_PNFA_ftd.shape)
labels_PNFA_ftd = np.full((len(PNFA_ftd_images),),3)
print('label_PNFA_ftd', labels_PNFA_ftd.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images,BV_ftd_images, SV_ftd_images,PNFA_ftd_images), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,label_BV_ftd,label_SV_ftd, label_PNFA_ftd), axis=0)
print('y data in  of train size: ', y.shape)

X.shape,y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(12,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset1 = TensorDataset(X,y)
validation_loader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=False)

torch.manual_seed(43)
query_list=[]
query_ys_list=[]
model.eval()
with torch.no_grad():
  for data in validation_loader:
    query_xs,query_ys = data
    batch_size, channel, height, width, depth = query_xs.size()
    query_xs = query_xs.view(-1, channel, height, width, depth)
    query_xs = query_xs.view(-1, channel, height, width,depth)
    feat_query = model_new(query_xs.data).view(query_xs.size(0), -1)
    feat_query = feat_query.detach().cpu().numpy()
    query_list.append(feat_query)
    #print(len(feat_query))
    query_ys = query_ys.view(-1).numpy()
    query_ys_list.append(query_ys)
    #print(len(query_ys))

query_list=np.vstack(query_list)
len(query_list)

query_ys_list= np.hstack(query_ys_list)
len(query_ys_list)

query_ys_list

"""#Logistic Regression"""

clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
clf.fit(support_list, support_ys_list)

clf.score(support_list, support_ys_list)

query_ys_pred = clf.predict(query_list)

acc_phi=[]
acc_phi.append(metrics.matthews_corrcoef(query_ys_list, query_ys_pred))

acc_phi

acc=[]
acc.append(metrics.accuracy_score(query_ys_list, query_ys_pred))

acc

from sklearn.metrics import classification_report
y_true = query_ys_list
y_pred = query_ys_pred
target_names = ['CN', 'FTD_BV','FTD_SV','FTD_PNFA']
print(classification_report(y_true, y_pred, target_names=target_names))

cnf_matrix=metrics.confusion_matrix(query_ys_list, query_ys_pred)
cnf_matrix

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#fig, ax = plt.subplots(figsize=(10, 5))
np.random.seed(0)

labels = ['CN', 'FTD_BV','FTD_SV','FTD_PNFA']

cm = confusion_matrix(query_ys_list, query_ys_pred)
ConfusionMatrixDisplay(cm, display_labels=labels).plot()

class_names=[0,1,2,3] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
# create heatmap
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

print("Accuracy:",metrics.accuracy_score(query_ys_list, query_ys_pred))

"""# Cross Validation"""

X=np.concatenate((support_list,query_list))
len(X)

y=np.concatenate((support_ys_list,query_ys_list))
len(y)

from sklearn.model_selection import cross_val_score
clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
scores = cross_val_score(clf, X, y, cv=5)
scores

print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))

