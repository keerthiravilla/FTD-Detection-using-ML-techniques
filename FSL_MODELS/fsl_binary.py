# -*- coding: utf-8 -*-
"""FSL_Binary

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L45bg1T-RSOlqp5tJiapG2zB5J0avKpJ
"""

# Commented out IPython magic to ensure Python compatibility.
#Multi-class Classification
import zipfile
import nibabel as nib
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.utils import make_grid
import numpy as np
import pandas as pd
import pickle
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import glob
from torch.autograd import Variable
from torchvision import models
from torch.nn import Module,  Linear, ReLU, CrossEntropyLoss, Sequential, Conv3d, MaxPool3d, Softmax, BatchNorm3d
from torch.optim import Adam
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import seaborn as sns
import torch.optim as optim
from sklearn.metrics import accuracy_score
from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import matthews_corrcoef
from sklearn.manifold import TSNE
from sklearn import metrics
from sklearn.svm import SVC, LinearSVC
from sklearn.linear_model import LogisticRegression
import scipy
from scipy.stats import t
from tqdm import tqdm
from torchsummary import summary
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('display.max_colwidth', None)
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive/')

import os
#walk through directory and list through files
for dirpath, dirnames, filenames in os.walk("/content/drive/My Drive/ADNI_full"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")
len(filenames)

#Get the class names
import numpy as np
import pathlib
data_dir = pathlib.Path('/content/drive/My Drive/ADNI_full')
class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))
print(class_names)

with open("/content/drive/MyDrive/Images_ADNI.txt", 'rb') as fp:
  X=pickle.load(fp)
  y=pickle.load(fp)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(663,1,100,100,55)

X.shape

model = torch.jit.load('/content/drive/MyDrive/feature_extractor.pt')
model.eval()

class ResNet(nn.Module):
    def __init__(self):
        super(ResNet, self).__init__()
        self.avgpool = nn.Sequential(*list(model.fc.children())[:-4]
        )
    def forward(self, x):
        x = self.avgpool(x).flatten(start_dim=1)
        return x


model_new = ResNet()

model_new.eval()

"""#Binary Classifcation"""

CN_ftd = glob.glob(r'/content/drive/MyDrive/FTD_Dataset/CN/*.nii')
CNftd_files = CN_ftd
CNfiles = len(CNftd_files)
print('The total number of nifti files:', str(CNfiles))
x_range_from = 10; x_range_to = 110
y_range_from = 40; y_range_to = 95
z_range_from = 5; z_range_to = 105

CN_ftd_images = np.zeros((CNfiles, z_range_to-z_range_from,x_range_to-x_range_from, y_range_to-y_range_from,1), 
                dtype=np.float32)
print(CN_ftd_images.shape)
#Load nifti files into array

for i in  range(CNfiles):
    if(i%10==0):
        print('Loading file %d of %d' % (i+1, CNfiles))
    CN_ftd_img = nib.load(CNftd_files[i])
    CN_ftd_img = CN_ftd_img.get_fdata()[x_range_from:x_range_to, y_range_from:y_range_to, z_range_from:z_range_to]
    CN_ftd_img = np.transpose(CN_ftd_img, (2,0,1))
    CN_ftd_img = np.flip(CN_ftd_img)
    
    CN_ftd_images[i, :,:,:, 0] = np.nan_to_num(CN_ftd_img)
print('Loaded files sucessfully')
print('Image array size:', CN_ftd_images.shape)

#Making y-labels
label_CN_ftd = np.full(len(CN_ftd_images),0)
print('label_CN_ftd', label_CN_ftd.shape)
label_CN_ftd = np.full((len(CN_ftd_images),),0)
print('label_CN_ftd', label_CN_ftd.shape)

ft_samples = glob.glob(r'/content/drive/MyDrive/FTD_Dataset/FTD/*.nii')
ft_files = ft_samples
ft_num_files = len(ft_files)

print('The total number of nifti files:', str(ft_num_files))

x_range_from = 10; x_range_to = 110
y_range_from = 40 ; y_range_to = 95
z_range_from = 5; z_range_to = 105

FTimages = np.zeros((ft_num_files, z_range_to-z_range_from, x_range_to-x_range_from,y_range_to-y_range_from,1),
                    dtype=np.float32)
print(FTimages.shape)
#Load nifti files into array
for i in range(ft_num_files):
    if (i%10==0):
        print('Loading file %d of %d' % (i+1, ft_num_files))
    FT_img = nib.load(ft_files[i])
    FT_img = FT_img.get_fdata()[x_range_from:x_range_to,y_range_from:y_range_to,z_range_from:z_range_to]
    FT_img = np.transpose(FT_img,(2,0,1))
    FT_img = np.flip(FT_img)
    
    FTimages[i, :,:,:, 0] = np.nan_to_num(FT_img)
print('Loaded files sucessfully')
print('Image array size:', FTimages.shape)

#y_labels for FT samples
FT_labels = np.full(len(FTimages),1)
print('FT_labels:', FT_labels.shape)
FT_labels = np.full((len(FTimages),),1)
print('FT_labels', FT_labels.shape)

#Concatenation of training data
X=np.concatenate((CN_ftd_images, FTimages), axis=0)
print('x data of train size: ', X.shape)
y=np.concatenate((label_CN_ftd,FT_labels), axis=0)
print('y data in  of train size: ', y.shape)

X.shape, y.shape

X = torch.from_numpy(X)
X.shape, X.dtype

X=X.reshape(279,1,100,100,55)

X.shape

X=X.expand(-1,3,-1,-1,-1)
X.shape

y = torch.from_numpy(y)
y.shape, y.dtype

from sklearn.model_selection import train_test_split
#batch_size=32
support_xs,query_xs, support_ys,query_ys =train_test_split(X,y, test_size=0.2, random_state=42)


(support_xs.shape, support_ys.shape),(query_xs.shape, query_ys.shape), (support_xs.dtype, support_ys.dtype), (query_xs.dtype, query_ys.dtype)

from torch.utils.data import DataLoader,TensorDataset
BATCH_SIZE = 10
dataset = TensorDataset(support_xs,support_ys)
dataset1 = TensorDataset(query_xs,query_ys)

test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)
validataion_loader = DataLoader(dataset1, batch_size=BATCH_SIZE,shuffle=False)

"""#Support Set Features"""

torch.manual_seed(21)
support_list=[]
support_ys_list=[]
model_new.eval()
with torch.no_grad():
  for data in test_loader:
    support_xs,support_ys = data
    batch_size, channel, height, width, depth = support_xs.size()
    support_xs = support_xs.view(-1, channel, height, width, depth)
    support_xs = support_xs.view(-1, channel, height, width,depth)
    feat_support = model_new(support_xs.data).view(support_xs.size(0), -1)
    feat_support = feat_support.detach().cpu().numpy()
    support_list.append(feat_support)
    #print(len(feat_support))
    support_ys = support_ys.view(-1).numpy()
    support_ys_list.append(support_ys)
    #print(len(support_ys))

support_list=np.vstack(support_list)
len(support_list)

support_ys_list= np.hstack(support_ys_list)
len(support_ys_list)

support_list.shape

"""#Query Set Features"""

torch.manual_seed(31)
query_list=[]
query_ys_list=[]
model.eval()
with torch.no_grad():
  for data in validataion_loader:
    query_xs,query_ys = data
    batch_size, channel, height, width, depth = query_xs.size()
    query_xs = query_xs.view(-1, channel, height, width, depth)
    query_xs = query_xs.view(-1, channel, height, width,depth)
    feat_query = model_new(query_xs.data).view(query_xs.size(0), -1)
    feat_query = feat_query.detach().cpu().numpy()
    query_list.append(feat_query)
    #print(len(feat_query))
    query_ys = query_ys.view(-1).numpy()
    query_ys_list.append(query_ys)
    #print(len(query_ys))

query_list=np.vstack(query_list)
len(query_list)

query_ys_list= np.hstack(query_ys_list)
len(query_ys_list)

"""#Logistic Regression"""

from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score
#Use to estimate the performance of the model based on accuracy, precision, recall, f1 score, AUC ROCCURVE, CM
def evaluation_metrics(Y_test, Y_pre, target_names):
    #scores
    print("Accuracy :",accuracy_score(Y_test,Y_pre))
    print("Precision :",precision_score(Y_test,Y_pre))
    print("Recall :",recall_score(Y_test,Y_pre))
    print("F1 Score :",f1_score(Y_test,Y_pre))

    print(classification_report(Y_test, Y_pre, target_names=target_names))

    #AUC
    fpr, tpr, _ = roc_curve(Y_test,Y_pre)
    auc = roc_auc_score(Y_test,Y_pre)
    print("AUC :", auc)

    #ROC
    plt.plot(fpr,tpr,label="uc={:.3f})".format(auc))
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False positive rate')
    plt.ylabel('True positive rate')
    plt.title('ROC curve')
    plt.legend(loc=4)
    plt.show()

    #CM matrix
    matrix = confusion_matrix(Y_test, Y_pre)
    cm = pd.DataFrame(matrix, index=target_names, columns=target_names)

    sns.heatmap(cm, annot=True, cbar=None, cmap="Blues", fmt = 'g')
    plt.title("Confusion Matrix"), plt.tight_layout()
    plt.ylabel("True Class"), plt.xlabel("Predicted Class")
    plt.show()

def logistic(X_train,X_test,Y_train,Y_test):
    model=LogisticRegression()
    model.fit(X_train,Y_train)
    Y_pre=model.predict(X_test)
    target_names = ['CN','FTD']
    evaluation_metrics(Y_test, Y_pre, target_names)

logistic(support_list, query_list,support_ys_list,query_ys_list)

clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
clf.fit(support_list, support_ys_list)

from sklearn import tree
plt.figure(figsize=(12,8)) 
tree.plot_tree(clf, filled=True, fontsize=10)
plt.show()

clf.score(support_list, support_ys_list)

query_ys_pred = clf.predict(query_list)

acc=[]
acc.append(metrics.accuracy_score(query_ys_list, query_ys_pred))

acc

acc_phi=[]
acc_phi.append(metrics.matthews_corrcoef(query_ys_list, query_ys_pred))

acc_phi

from sklearn.metrics import classification_report
y_true = query_ys_list
y_pred = query_ys_pred
target_names = ['CN', 'FTD']
print(classification_report(y_true, y_pred, target_names=target_names))

metrics.confusion_matrix(query_ys_list, query_ys_pred)

import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#fig, ax = plt.subplots(figsize=(10, 5))
np.random.seed(0)

labels = ['CN', 'FTD']

cm = confusion_matrix(query_ys_list, query_ys_pred)
ConfusionMatrixDisplay(cm, display_labels=labels).plot()

"""#Cross Validation"""

X=np.concatenate((support_list,query_list))
len(X)

y=np.concatenate((support_ys_list,query_ys_list))
len(y)

from sklearn.model_selection import cross_val_score
clf = LogisticRegression(penalty='l2',
                        random_state=0,
                        C=1.0,
                        solver='lbfgs',
                        max_iter=1000,
                        multi_class='multinomial')
scores = cross_val_score(clf, X, y, cv=5)
scores

print("%0.2f accuracy with a standard deviation of %0.2f" % (scores.mean(), scores.std()))

